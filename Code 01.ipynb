{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc6c2324",
   "metadata": {},
   "source": [
    "Loading the PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e9189e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = r\"R:\\Job\\FileSure Internship Project\\Form ADT-1-29092023_signed.pdf\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbd19dd",
   "metadata": {},
   "source": [
    "Checking that if correctly extracting information from the PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60b36389",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Page 1 ---\n",
      "FORM NO. ADT-1\n",
      "Notice to the Registrar by \n",
      "company for appointment of \n",
      "auditor\n",
      "[Pursuant to section 139 of the Companies Act, \n",
      "2013 and Rule 4(2) of the Companies  \n",
      "(Audit and Auditors) Rules, 2014]\n",
      "Form language\n",
      "English\n",
      "Hindi\n",
      "Refer the instruction kit for filing the form.\n",
      "Pre-fill\n",
      "U74999KA2016PTC095981\n",
      "1.(a) *Corporate identity number (CIN) of company\n",
      "(b)  Global location number (GLN) of company\n",
      "2.(a)  Name of the company\n",
      "ALUPA FOODS PRIVATE LIMITED\n",
      "DHANYALAXMI RICE MILL, \n",
      "5-110A, PUTTUR, \n",
      "UDUPI \n",
      "Udupi \n",
      "Karnataka \n",
      "576105\n",
      "(b) Address of the registered office  \n",
      "      of  the company\n",
      "*\n",
      "(c)   email id of the company\n",
      "mail@alupafoods.in\n",
      "3.(a)   Whether company is falling under any class of companies as per section 139(2)   \n",
      "Yes\n",
      "No\n",
      "*\n",
      "(b)   Nature of appointment    \n",
      "*\n",
      "Appointment/Re-appointment in AGM\n",
      "*\n",
      "4.   Whether joint auditors have been appointed\n",
      "Yes\n",
      "No\n",
      "Number of auditor(s) appointed\n",
      "*\n",
      "1\n",
      "Individual\n",
      "Auditor's Firm\n",
      "I. (a) *Category of Auditor\n",
      "(b) *Income Tax permanent account number of auditor or auditor's firm\n",
      "AABFM8893Q\n",
      "(c) *Name of the auditor or auditor's firm\n",
      "MALLYA & MALLYA\n",
      "(d) *Membership Number of auditor or auditor's firm's registration number\n",
      "001955S\n",
      "(e) *Address of the Auditor                    Line I \n",
      "        or auditor's firm\n",
      "29/2, 1st Floor, Parijatha Complex\n",
      "Line II\n",
      "Race Course Road\n",
      "Bangalore\n",
      "*City\n",
      "Karnataka-KA\n",
      "*State\n",
      "Country\n",
      "IN\n",
      "560001\n",
      "*Pin code\n",
      "*email id of the auditor  \n",
      "  or auditor's firm\n",
      "mallyaandmallya@gmail.com\n",
      "(DD/MM/YYYY)\n",
      "*\n",
      "(f)    Period of account for which appointed\n",
      "   From\n",
      "01/04/2022\n",
      "(DD/MM/YYYY)\n",
      "To\n",
      "31/03/2027\n",
      "*\n",
      "(g)   Number of financial year(s) to which appointment relates\n",
      "5\n",
      "(h)   Whether the appointment of auditor is within the limits of twenty companies as specified  \n",
      "        in sub section 3(g) of section 141\n",
      "Yes\n",
      "No\n",
      "*\n",
      "Page 1 of 3\n",
      "\n",
      "--- Page 2 ---\n",
      "(i) Specify the tenure of previous appointment(s) of the auditor or auditor's firm or its member in the same company in  \n",
      "     which audit was conducted or is functioning (excluding previous years having break of five or more years as specified   \n",
      "     in Rule 6)\n",
      "Number of financial year(s)\n",
      "*\n",
      "6\n",
      "Financial year \n",
      "End date\n",
      "S.no.\n",
      "Person appointed as auditor\n",
      "Financial year \n",
      "Start date\n",
      "Auditor's  Firm\n",
      "31/03/2017\n",
      "24/08/2016\n",
      "1.\n",
      "01/04/2017\n",
      "Auditor's  Firm\n",
      "31/03/2018\n",
      "2.\n",
      "Auditor's  Firm\n",
      "31/03/2019\n",
      "3.\n",
      "01/04/2018\n",
      "Auditor's  Firm\n",
      "31/03/2020\n",
      "4.\n",
      "01/04/2019\n",
      "Auditor's  Firm\n",
      "31/03/2021\n",
      "5.\n",
      "01/04/2020\n",
      "Auditor's  Firm\n",
      "31/03/2022\n",
      "6.\n",
      "01/04/2021\n",
      "7.\n",
      "8.\n",
      "9.\n",
      "10.\n",
      "Page 2 of 3\n",
      "\n",
      "--- Page 3 ---\n",
      "5. (a) *Whether auditor(s)  has been appointed in the annual general meeting (AGM)\n",
      "Yes\n",
      "No\n",
      "(b) If  yes, date of AGM\n",
      "(DD/MM/YYYY)\n",
      "26/09/2022\n",
      "6. *Date of appointment \n",
      "(DD/MM/YYYY)\n",
      "26/09/2022\n",
      "*\n",
      "7.   (a)   Whether auditor is appointed due to casual vacancy in the office of auditor\n",
      "Yes\n",
      "No\n",
      "*\n",
      "(b)   Specify the SRN of relevant form\n",
      "*\n",
      "(c)   Person vacated the office\n",
      "Individual\n",
      "Auditor's firm\n",
      "*\n",
      "(d)   Mention the membership number of auditor or Registration number of auditor's firm     \n",
      "        who has vacated the office\n",
      "*\n",
      "(e)   Mention the date of such vacancy\n",
      "*\n",
      "(f)    Reasons of the casual vacancy\n",
      "Attachments \n",
      "  \n",
      "1.  Copy of the intimation sent by company \n",
      "  \n",
      "2. *Copy of written consent given by auditor\n",
      "Attach\n",
      "List of Attachments\n",
      "Consent signed.pdf\n",
      "Resolution for appointment of Auditor Signed\n",
      "Intimation Letter Signed.pdf\n",
      "Acceptance signed.pdf\n",
      "Attach\n",
      "Attach\n",
      "3. *Copy of resolution passed by the board/company\n",
      "4.  Copy of the letter of appointment from C&AG\n",
      "Attach\n",
      "6.  Optional attachment(s) - if any\n",
      "Attach\n",
      "Remove attachment\n",
      "Declaration\n",
      "I am authorized by the Board of Directors of the Company vide resolution number *                           dated *                \n",
      "to sign this form and declare that all the requirements of Companies Act, 2013 and the rules made thereunder in respect of the \n",
      "subject matter of this form and matters incidental thereto have been complied with. I also declare that all the information given \n",
      "herein above is true, correct and complete including the attachments to this form and nothing material has been suppressed.\n",
      "007\n",
      "29/08/2022\n",
      "*\n",
      "To be digitally signed by\n",
      "Digitally signed by \n",
      "Krishna Kumar Rao \n",
      "Date: 2022.11.23 \n",
      "18:01:53 +05'30'\n",
      "Krishna \n",
      "Kumar Rao\n",
      "*\n",
      "Designation\n",
      "Director\n",
      "Director identification number of the director; or DIN or \n",
      "PAN of the Manager/CEO/CFO; or Membership number of \n",
      "the Company Secretary\n",
      "*\n",
      "07579495\n",
      "Note: Attention is also drawn to provisions of Section 448 of the Companies Act which provide for punishment for false \n",
      "statement.\n",
      "Submit\n",
      "Prescrutiny\n",
      "Check Form\n",
      "Modify\n",
      "This eForm has been taken on file maintained by the registrar of companies through electronic mode and on the basis of \n",
      "statement of correctness given by the company.\n",
      "Page 3 of 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"FORM NO. ADT-1\\nNotice to the Registrar by \\ncompany for appointment of \\nauditor\\n[Pursuant to section 139 of the Companies Act, \\n2013 and Rule 4(2) of the Companies  \\n(Audit and Auditors) Rules, 2014]\\nForm language\\nEnglish\\nHindi\\nRefer the instruction kit for filing the form.\\nPre-fill\\nU74999KA2016PTC095981\\n1.(a) *Corporate identity number (CIN) of company\\n(b)  Global location number (GLN) of company\\n2.(a)  Name of the company\\nALUPA FOODS PRIVATE LIMITED\\nDHANYALAXMI RICE MILL, \\n5-110A, PUTTUR, \\nUDUPI \\nUdupi \\nKarnataka \\n576105\\n(b) Address of the registered office  \\n      of  the company\\n*\\n(c)   email id of the company\\nmail@alupafoods.in\\n3.(a)   Whether company is falling under any class of companies as per section 139(2)   \\nYes\\nNo\\n*\\n(b)   Nature of appointment    \\n*\\nAppointment/Re-appointment in AGM\\n*\\n4.   Whether joint auditors have been appointed\\nYes\\nNo\\nNumber of auditor(s) appointed\\n*\\n1\\nIndividual\\nAuditor's Firm\\nI. (a) *Category of Auditor\\n(b) *Income Tax permanent account number of auditor or auditor's firm\\nAABFM8893Q\\n(c) *Name of the auditor or auditor's firm\\nMALLYA & MALLYA\\n(d) *Membership Number of auditor or auditor's firm's registration number\\n001955S\\n(e) *Address of the Auditor                    Line I \\n        or auditor's firm\\n29/2, 1st Floor, Parijatha Complex\\nLine II\\nRace Course Road\\nBangalore\\n*City\\nKarnataka-KA\\n*State\\nCountry\\nIN\\n560001\\n*Pin code\\n*email id of the auditor  \\n  or auditor's firm\\nmallyaandmallya@gmail.com\\n(DD/MM/YYYY)\\n*\\n(f)    Period of account for which appointed\\n   From\\n01/04/2022\\n(DD/MM/YYYY)\\nTo\\n31/03/2027\\n*\\n(g)   Number of financial year(s) to which appointment relates\\n5\\n(h)   Whether the appointment of auditor is within the limits of twenty companies as specified  \\n        in sub section 3(g) of section 141\\nYes\\nNo\\n*\\nPage 1 of 3\\n(i) Specify the tenure of previous appointment(s) of the auditor or auditor's firm or its member in the same company in  \\n     which audit was conducted or is functioning (excluding previous years having break of five or more years as specified   \\n     in Rule 6)\\nNumber of financial year(s)\\n*\\n6\\nFinancial year \\nEnd date\\nS.no.\\nPerson appointed as auditor\\nFinancial year \\nStart date\\nAuditor's  Firm\\n31/03/2017\\n24/08/2016\\n1.\\n01/04/2017\\nAuditor's  Firm\\n31/03/2018\\n2.\\nAuditor's  Firm\\n31/03/2019\\n3.\\n01/04/2018\\nAuditor's  Firm\\n31/03/2020\\n4.\\n01/04/2019\\nAuditor's  Firm\\n31/03/2021\\n5.\\n01/04/2020\\nAuditor's  Firm\\n31/03/2022\\n6.\\n01/04/2021\\n7.\\n8.\\n9.\\n10.\\nPage 2 of 3\\n5. (a) *Whether auditor(s)  has been appointed in the annual general meeting (AGM)\\nYes\\nNo\\n(b) If  yes, date of AGM\\n(DD/MM/YYYY)\\n26/09/2022\\n6. *Date of appointment \\n(DD/MM/YYYY)\\n26/09/2022\\n*\\n7.   (a)   Whether auditor is appointed due to casual vacancy in the office of auditor\\nYes\\nNo\\n*\\n(b)   Specify the SRN of relevant form\\n*\\n(c)   Person vacated the office\\nIndividual\\nAuditor's firm\\n*\\n(d)   Mention the membership number of auditor or Registration number of auditor's firm     \\n        who has vacated the office\\n*\\n(e)   Mention the date of such vacancy\\n*\\n(f)    Reasons of the casual vacancy\\nAttachments \\n  \\n1.  Copy of the intimation sent by company \\n  \\n2. *Copy of written consent given by auditor\\nAttach\\nList of Attachments\\nConsent signed.pdf\\nResolution for appointment of Auditor Signed\\nIntimation Letter Signed.pdf\\nAcceptance signed.pdf\\nAttach\\nAttach\\n3. *Copy of resolution passed by the board/company\\n4.  Copy of the letter of appointment from C&AG\\nAttach\\n6.  Optional attachment(s) - if any\\nAttach\\nRemove attachment\\nDeclaration\\nI am authorized by the Board of Directors of the Company vide resolution number *                           dated *                \\nto sign this form and declare that all the requirements of Companies Act, 2013 and the rules made thereunder in respect of the \\nsubject matter of this form and matters incidental thereto have been complied with. I also declare that all the information given \\nherein above is true, correct and complete including the attachments to this form and nothing material has been suppressed.\\n007\\n29/08/2022\\n*\\nTo be digitally signed by\\nDigitally signed by \\nKrishna Kumar Rao \\nDate: 2022.11.23 \\n18:01:53 +05'30'\\nKrishna \\nKumar Rao\\n*\\nDesignation\\nDirector\\nDirector identification number of the director; or DIN or \\nPAN of the Manager/CEO/CFO; or Membership number of \\nthe Company Secretary\\n*\\n07579495\\nNote: Attention is also drawn to provisions of Section 448 of the Companies Act which provide for punishment for false \\nstatement.\\nSubmit\\nPrescrutiny\\nCheck Form\\nModify\\nThis eForm has been taken on file maintained by the registrar of companies through electronic mode and on the basis of \\nstatement of correctness given by the company.\\nPage 3 of 3\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import fitz \n",
    "\n",
    "def extract_text_preserving_order(pdf_path):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    all_text = \"\"\n",
    "    for page_num, page in enumerate(doc):\n",
    "        blocks = page.get_text(\"blocks\")\n",
    "        blocks = sorted(blocks, key=lambda b: (b[1], b[0]))\n",
    "\n",
    "        print(f\"\\n--- Page {page_num + 1} ---\")\n",
    "        for block in blocks:\n",
    "            block_text = block[4].strip()\n",
    "            if block_text:\n",
    "                print(block_text)\n",
    "                all_text += block_text + \"\\n\"\n",
    "    return all_text\n",
    "\n",
    "\n",
    "extract_text_preserving_order(pdf_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb76a46",
   "metadata": {},
   "source": [
    "Creating a json file with upper extracted information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e22756df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "import pandas as pd\n",
    "\n",
    "def extract_text_as_table(pdf_path, y_threshold=10):\n",
    "    doc = fitz.open(pdf_path)\n",
    "    all_rows = []\n",
    "\n",
    "    for page_num, page in enumerate(doc, start=1):\n",
    "        blocks = page.get_text(\"blocks\")\n",
    "        blocks = [b for b in blocks if b[4].strip()]  # Filter empty text\n",
    "        # Sort blocks top to bottom, left to right\n",
    "        blocks = sorted(blocks, key=lambda b: (b[1], b[0]))\n",
    "\n",
    "        # Group blocks into rows based on y0 proximity\n",
    "        rows = []\n",
    "        current_row = []\n",
    "        last_y = None\n",
    "\n",
    "        for b in blocks:\n",
    "            x0, y0, x1, y1, text, block_no, block_type = b\n",
    "            if last_y is None:\n",
    "                current_row.append(b)\n",
    "                last_y = y0\n",
    "            else:\n",
    "                if abs(y0 - last_y) <= y_threshold:\n",
    "                    current_row.append(b)\n",
    "                    last_y = (last_y + y0) / 2  # average for smoothing\n",
    "                else:\n",
    "                    rows.append(current_row)\n",
    "                    current_row = [b]\n",
    "                    last_y = y0\n",
    "        if current_row:\n",
    "            rows.append(current_row)\n",
    "\n",
    "        # For each row, sort blocks by x0 and collect texts as columns\n",
    "        for row_blocks in rows:\n",
    "            row_blocks = sorted(row_blocks, key=lambda b: b[0])  # sort by x0\n",
    "            row_texts = [b[4].strip() for b in row_blocks]\n",
    "            all_rows.append([page_num] + row_texts)\n",
    "\n",
    "    # Normalize rows to equal columns\n",
    "    max_cols = max(len(r) for r in all_rows)\n",
    "    for r in all_rows:\n",
    "        while len(r) < max_cols:\n",
    "            r.append(\"\")\n",
    "\n",
    "    columns = [\"Page\"] + [f\"Col_{i}\" for i in range(1, max_cols)]\n",
    "    df = pd.DataFrame(all_rows, columns=columns)\n",
    "    return df\n",
    "\n",
    "# File path\n",
    "\n",
    "\n",
    "# Extract table\n",
    "df_table = extract_text_as_table(pdf_path)\n",
    "\n",
    "\n",
    "\n",
    "# Save as JSON\n",
    "df_table.to_json(\"pdf_extracted_table.json\", orient=\"records\", indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95b1bc6",
   "metadata": {},
   "source": [
    "Creating New Organized Json File and deleting the old json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62751470",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"pdf_extracted_table.json\"\n",
    "output_file = \"final_qa_output.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5cf3811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved output to 'final_qa_output.json' and deleted 'pdf_extracted_table.json'\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "import os\n",
    "\n",
    "def clean(text):\n",
    "    return re.sub(r'\\s+', ' ', text.replace('\\n', ' ')).strip()\n",
    "\n",
    "def is_unwanted_line(text):\n",
    "    # Matches \"7.\", \"10.\", etc.\n",
    "    if re.fullmatch(r'\\d+\\.', text):\n",
    "        return True\n",
    "    # Matches \"Page 2 of 3\", \"Page 10 of 10\"\n",
    "    if re.fullmatch(r'Page \\d+ of \\d+', text, re.IGNORECASE):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def is_blank_answer(text):\n",
    "    return not text or text == \"*\"\n",
    "\n",
    "\n",
    "\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "qa_dict = {}\n",
    "\n",
    "for item in data:\n",
    "    col1 = clean(item.get(\"Col_1\", \"\"))\n",
    "    col2 = clean(item.get(\"Col_2\", \"\"))\n",
    "    col3 = clean(item.get(\"Col_3\", \"\"))\n",
    "\n",
    "    # Skip rows where all blank or '*'\n",
    "    if is_blank_answer(col1) and is_blank_answer(col2) and is_blank_answer(col3):\n",
    "        continue\n",
    "\n",
    "    # Skip unwanted lines\n",
    "    if is_unwanted_line(col1):\n",
    "        continue\n",
    "\n",
    "    # Skip if no answers in col2 and col3\n",
    "    if is_blank_answer(col2) and is_blank_answer(col3):\n",
    "        continue\n",
    "\n",
    "    # Compose answer from col2 and col3\n",
    "    answer = col2\n",
    "    if not is_blank_answer(col3):\n",
    "        answer += \" \" + col3\n",
    "\n",
    "    qa_dict[col1] = answer.strip()\n",
    "\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(qa_dict, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "try:\n",
    "    os.remove(input_file)\n",
    "    print(f\"Saved output to '{output_file}' and deleted '{input_file}'\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not delete input file: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7485d5dd",
   "metadata": {},
   "source": [
    "Summary of the Json File using hugging face model and creating a summary txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78216be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated summary \n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from transformers import pipeline, AutoTokenizer\n",
    "\n",
    "\n",
    "with open(\"final_qa_output.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    qa_data = json.load(f)\n",
    "\n",
    "\n",
    "def fuse_qa(q, a):\n",
    "    q = q.strip(\"?\").strip()\n",
    "    return f\"{q} is {a.strip()}.\"\n",
    "\n",
    "full_text = \" \".join([fuse_qa(q, a) for q, a in qa_data.items() if a.strip() != \"*\"])\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-large-cnn\")\n",
    "encoded_input = tokenizer.encode(full_text, max_length=512, truncation=True, add_special_tokens=True)\n",
    "truncated_text = tokenizer.decode(encoded_input, skip_special_tokens=True)\n",
    "\n",
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "summary = summarizer(\n",
    "    truncated_text,\n",
    "    max_length=500,\n",
    "    min_length=200,\n",
    "    length_penalty=2.0,\n",
    "    no_repeat_ngram_size=3,\n",
    "    do_sample=False\n",
    ")[0][\"summary_text\"]\n",
    "\n",
    "# Save result\n",
    "output_path = Path(\"Summary_of_Json.md\")\n",
    "output_path.write_text(f\"# Automated Summary\\n\\n{summary}\", encoding=\"utf-8\")\n",
    "\n",
    "print(\"Generated summary \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8333b1c7",
   "metadata": {},
   "source": [
    "Extractinng the Embedded pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ab130e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text extracted to: extracted_content\\extracted_text.txt\n",
      "Images extracted to: extracted_content\\images\n",
      "Tables extracted to: extracted_content\\tables\n",
      "Attachment saved: extracted_content\\attachments\\IntimationLetterSigned.pdf\n",
      "Attachment saved: extracted_content\\attachments\\Consentsigned.pdf\n",
      "Attachment saved: extracted_content\\attachments\\ResolutionforappointmentofAuditorSigned.pdf\n",
      "Failed to extract attachment 3: 'utf-8' codec can't encode characters in position 14-15: surrogates not allowed\n",
      "All content extracted successfully!\n"
     ]
    }
   ],
   "source": [
    "import fitz  \n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "def extract_all_from_pdf(pdf_path, output_folder):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    doc = fitz.open(pdf_path)\n",
    "\n",
    "    text_output = os.path.join(output_folder, \"extracted_text.txt\")\n",
    "    with open(text_output, \"w\", encoding=\"utf-8\") as f:\n",
    "        for page in doc:\n",
    "            f.write(page.get_text())\n",
    "\n",
    "    print(f\"Text extracted to: {text_output}\")\n",
    "\n",
    "    # 2. Extract Images\n",
    "    images_folder = os.path.join(output_folder, \"images\")\n",
    "    os.makedirs(images_folder, exist_ok=True)\n",
    "    \n",
    "    for i, page in enumerate(doc):\n",
    "        img_list = page.get_images(full=True)\n",
    "        for img_index, img in enumerate(img_list):\n",
    "            xref = img[0]\n",
    "            base_image = doc.extract_image(xref)\n",
    "            img_bytes = base_image[\"image\"]\n",
    "            img_ext = base_image[\"ext\"]\n",
    "            img_path = os.path.join(images_folder, f\"page_{i+1}_img_{img_index}.{img_ext}\")\n",
    "            \n",
    "            with open(img_path, \"wb\") as f:\n",
    "                f.write(img_bytes)\n",
    "    \n",
    "    print(f\"Images extracted to: {images_folder}\")\n",
    "\n",
    "    # 3. Extract Tables (using PyMuPDF + Pandas)\n",
    "    tables_folder = os.path.join(output_folder, \"tables\")\n",
    "    os.makedirs(tables_folder, exist_ok=True)\n",
    "    \n",
    "    for i, page in enumerate(doc):\n",
    "        tables = page.find_tables()\n",
    "        if tables.tables:\n",
    "            for table_num, table in enumerate(tables.tables):\n",
    "                df = table.to_pandas()\n",
    "                csv_path = os.path.join(tables_folder, f\"page_{i+1}_table_{table_num}.csv\")\n",
    "                df.to_csv(csv_path, index=False)\n",
    "    \n",
    "    print(f\"Tables extracted to: {tables_folder}\")\n",
    "\n",
    "    # 4. Extract Attachments\n",
    "    attachments_folder = os.path.join(output_folder, \"attachments\")\n",
    "    os.makedirs(attachments_folder, exist_ok=True)\n",
    "    \n",
    "    for i in range(doc.embfile_count()):\n",
    "        try:\n",
    "            info = doc.embfile_info(i)\n",
    "            filename = info.get(\"filename\", f\"attachment_{i}\")\n",
    "            filename = \"\".join(c for c in filename if c.isalnum() or c in ('.', '_', '-')).strip()\n",
    "            \n",
    "            if not filename:\n",
    "                filename = f\"attachment_{i}\"\n",
    "            \n",
    "            file_data = doc.embfile_get(i)\n",
    "            attachment_path = os.path.join(attachments_folder, filename)\n",
    "            \n",
    "            with open(attachment_path, \"wb\") as f:\n",
    "                f.write(file_data)\n",
    "            \n",
    "            print(f\"Attachment saved: {attachment_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to extract attachment {i}: {e}\")\n",
    "\n",
    "    doc.close()\n",
    "    print(\"All content extracted successfully!\")\n",
    "\n",
    "\n",
    "\n",
    "output_folder = \"extracted_content\"\n",
    "extract_all_from_pdf(pdf_path, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d6ebc6d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary saved at: R:\\Job\\FileSure Internship Project\\Codes\\Embedded_System_Summary.md\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from transformers import pipeline\n",
    "\n",
    "def generate_summary(extraction_folder, output_file=r\"R:\\Job\\FileSure Internship Project\\Codes\\Embedded_System_Summary.md\"):\n",
    "    summary = {}\n",
    "    extraction_folder = Path(extraction_folder)\n",
    "    text_path = extraction_folder / \"extracted_text.txt\"\n",
    "\n",
    "    # Detect text\n",
    "    if text_path.exists():\n",
    "        text = text_path.read_text(encoding=\"utf-8\")\n",
    "        summary[\"text\"] = {\n",
    "            \"word_count\": len(text.split()),\n",
    "            \"char_count\": len(text),\n",
    "            \"sample\": text[:100] + \"...\" if len(text) > 100 else text\n",
    "        }\n",
    "\n",
    "    # Detect subfolders and their contents\n",
    "    for item in extraction_folder.iterdir():\n",
    "        if item.is_dir():\n",
    "            content_type = item.name.lower()\n",
    "            files = list(item.iterdir())\n",
    "            file_list = [f.name for f in files if f.is_file()]\n",
    "            if not file_list:\n",
    "                continue\n",
    "\n",
    "            # Heuristics: map folder type based on file extensions\n",
    "            if any(f.suffix.lower() == \".csv\" for f in files):\n",
    "                summary[\"tables\"] = {\n",
    "                    \"folder\": item.name,\n",
    "                    \"count\": len(file_list),\n",
    "                    \"sample\": file_list[:2]\n",
    "                }\n",
    "            elif any(f.suffix.lower() in [\".png\", \".jpg\", \".jpeg\"] for f in files):\n",
    "                summary[\"images\"] = {\n",
    "                    \"folder\": item.name,\n",
    "                    \"count\": len(file_list),\n",
    "                    \"sample\": file_list[:2]\n",
    "                }\n",
    "            elif any(f.suffix for f in files):\n",
    "                summary[\"attachments\"] = {\n",
    "                    \"folder\": item.name,\n",
    "                    \"count\": len(file_list),\n",
    "                    \"sample\": file_list[:10]\n",
    "                }\n",
    "\n",
    "    # Optional: AI-based text summarization\n",
    "    try:\n",
    "        if \"text\" in summary and len(summary[\"text\"][\"sample\"]) > 50:\n",
    "            summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\", device=0)\n",
    "            ai_summary = summarizer(summary[\"text\"][\"sample\"], max_length=36, min_length=30, do_sample=False)[0][\"summary_text\"]\n",
    "            summary[\"ai_summary\"] = ai_summary\n",
    "    except Exception as e:\n",
    "        summary[\"ai_summary\"] = f\"[AI summary failed: {str(e)}]\"\n",
    "\n",
    "    # Write summary\n",
    "    output_path = extraction_folder / output_file\n",
    "    with output_path.open(\"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"# PDF Extraction Summary\\n\\n\")\n",
    "        if \"text\" in summary:\n",
    "            f.write(\"## Text\\n\")\n",
    "            f.write(f\"- Words: {summary['text']['word_count']}\\n\")\n",
    "            f.write(f\"- Chars: {summary['text']['char_count']}\\n\")\n",
    "            f.write(f\"- Sample: {summary['text']['sample']}\\n\\n\")\n",
    "        for key in [\"tables\", \"images\", \"attachments\"]:\n",
    "            if key in summary:\n",
    "                f.write(f\"## {key.capitalize()}\\n\")\n",
    "                f.write(f\"- Folder: {summary[key]['folder']}\\n\")\n",
    "                f.write(f\"- Count: {summary[key]['count']}\\n\")\n",
    "                f.write(f\"- Sample: {summary[key]['sample']}\\n\\n\")\n",
    "        if \"ai_summary\" in summary:\n",
    "            f.write(\"## AI Summary\\n\")\n",
    "            f.write(summary[\"ai_summary\"] + \"\\n\")\n",
    "\n",
    "    print(f\"Summary saved at: {output_path}\")\n",
    "\n",
    "# Example usage\n",
    "generate_summary(\"extracted_content\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
